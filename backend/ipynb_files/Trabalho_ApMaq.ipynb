{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svk9vvA9_C7S"
      },
      "source": [
        "Os efeitos de status socioeconomico sobre obesidade - Thuanny Helen, Fredson Arthur e Maria Eduarda Santos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVnyMIeddxS8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import traceback\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import randint, uniform  # Distribuições estatísticas\n",
        "import re\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    RandomizedSearchCV,\n",
        "    cross_val_score,\n",
        "    KFold\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        "    make_scorer\n",
        ")\n",
        "import joblib\n",
        "from sklearn import set_config\n",
        "\n",
        "# Configurar estilo de plots\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# Configurar warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jlTA0zRIeEij",
        "outputId": "ccac3dec-d3d5-476f-f0da-db8dda0cca02"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0a15521d-5ed2-4513-94f8-5c033889c528\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YearStart</th>\n",
              "      <th>YearEnd</th>\n",
              "      <th>LocationAbbr</th>\n",
              "      <th>LocationDesc</th>\n",
              "      <th>Datasource</th>\n",
              "      <th>Class</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Question</th>\n",
              "      <th>Data_Value_Unit</th>\n",
              "      <th>Data_Value_Type</th>\n",
              "      <th>Data_Value</th>\n",
              "      <th>Data_Value_Alt</th>\n",
              "      <th>Data_Value_Footnote_Symbol</th>\n",
              "      <th>Data_Value_Footnote</th>\n",
              "      <th>Low_Confidence_Limit</th>\n",
              "      <th>High_Confidence_Limit</th>\n",
              "      <th>Sample_Size</th>\n",
              "      <th>Total</th>\n",
              "      <th>Age(years)</th>\n",
              "      <th>Education</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Income</th>\n",
              "      <th>Race/Ethnicity</th>\n",
              "      <th>GeoLocation</th>\n",
              "      <th>ClassID</th>\n",
              "      <th>TopicID</th>\n",
              "      <th>QuestionID</th>\n",
              "      <th>DataValueTypeID</th>\n",
              "      <th>LocationID</th>\n",
              "      <th>StratificationCategory1</th>\n",
              "      <th>Stratification1</th>\n",
              "      <th>StratificationCategoryId1</th>\n",
              "      <th>StratificationID1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011</td>\n",
              "      <td>2011</td>\n",
              "      <td>AL</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Percent of adults aged 18 years and older who ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.5</td>\n",
              "      <td>33.5</td>\n",
              "      <td>7304.0</td>\n",
              "      <td>Total</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(32.84057112200048, -86.63186076199969)</td>\n",
              "      <td>OWS</td>\n",
              "      <td>OWS1</td>\n",
              "      <td>Q036</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>1</td>\n",
              "      <td>Total</td>\n",
              "      <td>Total</td>\n",
              "      <td>OVR</td>\n",
              "      <td>OVERALL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>2011</td>\n",
              "      <td>AL</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Percent of adults aged 18 years and older who ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>32.3</td>\n",
              "      <td>32.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.9</td>\n",
              "      <td>34.7</td>\n",
              "      <td>2581.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(32.84057112200048, -86.63186076199969)</td>\n",
              "      <td>OWS</td>\n",
              "      <td>OWS1</td>\n",
              "      <td>Q036</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>1</td>\n",
              "      <td>Gender</td>\n",
              "      <td>Male</td>\n",
              "      <td>GEN</td>\n",
              "      <td>MALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011</td>\n",
              "      <td>2011</td>\n",
              "      <td>AL</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Percent of adults aged 18 years and older who ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>31.8</td>\n",
              "      <td>31.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>4723.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(32.84057112200048, -86.63186076199969)</td>\n",
              "      <td>OWS</td>\n",
              "      <td>OWS1</td>\n",
              "      <td>Q036</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>1</td>\n",
              "      <td>Gender</td>\n",
              "      <td>Female</td>\n",
              "      <td>GEN</td>\n",
              "      <td>FEMALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011</td>\n",
              "      <td>2011</td>\n",
              "      <td>AL</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Percent of adults aged 18 years and older who ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>33.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.9</td>\n",
              "      <td>37.6</td>\n",
              "      <td>1153.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Less than high school</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(32.84057112200048, -86.63186076199969)</td>\n",
              "      <td>OWS</td>\n",
              "      <td>OWS1</td>\n",
              "      <td>Q036</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>1</td>\n",
              "      <td>Education</td>\n",
              "      <td>Less than high school</td>\n",
              "      <td>EDU</td>\n",
              "      <td>EDUHS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011</td>\n",
              "      <td>2011</td>\n",
              "      <td>AL</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Obesity / Weight Status</td>\n",
              "      <td>Percent of adults aged 18 years and older who ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>32.8</td>\n",
              "      <td>32.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.2</td>\n",
              "      <td>35.6</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>High school graduate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(32.84057112200048, -86.63186076199969)</td>\n",
              "      <td>OWS</td>\n",
              "      <td>OWS1</td>\n",
              "      <td>Q036</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>1</td>\n",
              "      <td>Education</td>\n",
              "      <td>High school graduate</td>\n",
              "      <td>EDU</td>\n",
              "      <td>EDUHSGRAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53387</th>\n",
              "      <td>2016</td>\n",
              "      <td>2016</td>\n",
              "      <td>VI</td>\n",
              "      <td>Virgin Islands</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Physical Activity</td>\n",
              "      <td>Physical Activity - Behavior</td>\n",
              "      <td>Percent of adults who engage in no leisure-tim...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>~</td>\n",
              "      <td>Data not available because sample size is insu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Asian</td>\n",
              "      <td>(18.335765, -64.896335)</td>\n",
              "      <td>PA</td>\n",
              "      <td>PA1</td>\n",
              "      <td>Q047</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>78</td>\n",
              "      <td>Race/Ethnicity</td>\n",
              "      <td>Asian</td>\n",
              "      <td>RACE</td>\n",
              "      <td>RACEASN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53388</th>\n",
              "      <td>2016</td>\n",
              "      <td>2016</td>\n",
              "      <td>VI</td>\n",
              "      <td>Virgin Islands</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Physical Activity</td>\n",
              "      <td>Physical Activity - Behavior</td>\n",
              "      <td>Percent of adults who engage in no leisure-tim...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>~</td>\n",
              "      <td>Data not available because sample size is insu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hawaiian/Pacific Islander</td>\n",
              "      <td>(18.335765, -64.896335)</td>\n",
              "      <td>PA</td>\n",
              "      <td>PA1</td>\n",
              "      <td>Q047</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>78</td>\n",
              "      <td>Race/Ethnicity</td>\n",
              "      <td>Hawaiian/Pacific Islander</td>\n",
              "      <td>RACE</td>\n",
              "      <td>RACEHPI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53389</th>\n",
              "      <td>2016</td>\n",
              "      <td>2016</td>\n",
              "      <td>VI</td>\n",
              "      <td>Virgin Islands</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Physical Activity</td>\n",
              "      <td>Physical Activity - Behavior</td>\n",
              "      <td>Percent of adults who engage in no leisure-tim...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>~</td>\n",
              "      <td>Data not available because sample size is insu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>American Indian/Alaska Native</td>\n",
              "      <td>(18.335765, -64.896335)</td>\n",
              "      <td>PA</td>\n",
              "      <td>PA1</td>\n",
              "      <td>Q047</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>78</td>\n",
              "      <td>Race/Ethnicity</td>\n",
              "      <td>American Indian/Alaska Native</td>\n",
              "      <td>RACE</td>\n",
              "      <td>RACENAA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53390</th>\n",
              "      <td>2016</td>\n",
              "      <td>2016</td>\n",
              "      <td>VI</td>\n",
              "      <td>Virgin Islands</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Physical Activity</td>\n",
              "      <td>Physical Activity - Behavior</td>\n",
              "      <td>Percent of adults who engage in no leisure-tim...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>~</td>\n",
              "      <td>Data not available because sample size is insu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2 or more races</td>\n",
              "      <td>(18.335765, -64.896335)</td>\n",
              "      <td>PA</td>\n",
              "      <td>PA1</td>\n",
              "      <td>Q047</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>78</td>\n",
              "      <td>Race/Ethnicity</td>\n",
              "      <td>2 or more races</td>\n",
              "      <td>RACE</td>\n",
              "      <td>RACE2PLUS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53391</th>\n",
              "      <td>2016</td>\n",
              "      <td>2016</td>\n",
              "      <td>VI</td>\n",
              "      <td>Virgin Islands</td>\n",
              "      <td>Behavioral Risk Factor Surveillance System</td>\n",
              "      <td>Physical Activity</td>\n",
              "      <td>Physical Activity - Behavior</td>\n",
              "      <td>Percent of adults who engage in no leisure-tim...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>~</td>\n",
              "      <td>Data not available because sample size is insu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Other</td>\n",
              "      <td>(18.335765, -64.896335)</td>\n",
              "      <td>PA</td>\n",
              "      <td>PA1</td>\n",
              "      <td>Q047</td>\n",
              "      <td>VALUE</td>\n",
              "      <td>78</td>\n",
              "      <td>Race/Ethnicity</td>\n",
              "      <td>Other</td>\n",
              "      <td>RACE</td>\n",
              "      <td>RACEOTH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53392 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a15521d-5ed2-4513-94f8-5c033889c528')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a15521d-5ed2-4513-94f8-5c033889c528 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a15521d-5ed2-4513-94f8-5c033889c528');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-280d0dd7-2f4f-494b-b6db-ff1238a8c2f3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-280d0dd7-2f4f-494b-b6db-ff1238a8c2f3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-280d0dd7-2f4f-494b-b6db-ff1238a8c2f3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_59b303b1-540d-4e31-80c5-ff4de4d10c6e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_59b303b1-540d-4e31-80c5-ff4de4d10c6e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       YearStart  YearEnd LocationAbbr    LocationDesc  \\\n",
              "0           2011     2011           AL         Alabama   \n",
              "1           2011     2011           AL         Alabama   \n",
              "2           2011     2011           AL         Alabama   \n",
              "3           2011     2011           AL         Alabama   \n",
              "4           2011     2011           AL         Alabama   \n",
              "...          ...      ...          ...             ...   \n",
              "53387       2016     2016           VI  Virgin Islands   \n",
              "53388       2016     2016           VI  Virgin Islands   \n",
              "53389       2016     2016           VI  Virgin Islands   \n",
              "53390       2016     2016           VI  Virgin Islands   \n",
              "53391       2016     2016           VI  Virgin Islands   \n",
              "\n",
              "                                       Datasource                    Class  \\\n",
              "0      Behavioral Risk Factor Surveillance System  Obesity / Weight Status   \n",
              "1      Behavioral Risk Factor Surveillance System  Obesity / Weight Status   \n",
              "2      Behavioral Risk Factor Surveillance System  Obesity / Weight Status   \n",
              "3      Behavioral Risk Factor Surveillance System  Obesity / Weight Status   \n",
              "4      Behavioral Risk Factor Surveillance System  Obesity / Weight Status   \n",
              "...                                           ...                      ...   \n",
              "53387  Behavioral Risk Factor Surveillance System        Physical Activity   \n",
              "53388  Behavioral Risk Factor Surveillance System        Physical Activity   \n",
              "53389  Behavioral Risk Factor Surveillance System        Physical Activity   \n",
              "53390  Behavioral Risk Factor Surveillance System        Physical Activity   \n",
              "53391  Behavioral Risk Factor Surveillance System        Physical Activity   \n",
              "\n",
              "                              Topic  \\\n",
              "0           Obesity / Weight Status   \n",
              "1           Obesity / Weight Status   \n",
              "2           Obesity / Weight Status   \n",
              "3           Obesity / Weight Status   \n",
              "4           Obesity / Weight Status   \n",
              "...                             ...   \n",
              "53387  Physical Activity - Behavior   \n",
              "53388  Physical Activity - Behavior   \n",
              "53389  Physical Activity - Behavior   \n",
              "53390  Physical Activity - Behavior   \n",
              "53391  Physical Activity - Behavior   \n",
              "\n",
              "                                                Question  Data_Value_Unit  \\\n",
              "0      Percent of adults aged 18 years and older who ...              NaN   \n",
              "1      Percent of adults aged 18 years and older who ...              NaN   \n",
              "2      Percent of adults aged 18 years and older who ...              NaN   \n",
              "3      Percent of adults aged 18 years and older who ...              NaN   \n",
              "4      Percent of adults aged 18 years and older who ...              NaN   \n",
              "...                                                  ...              ...   \n",
              "53387  Percent of adults who engage in no leisure-tim...              NaN   \n",
              "53388  Percent of adults who engage in no leisure-tim...              NaN   \n",
              "53389  Percent of adults who engage in no leisure-tim...              NaN   \n",
              "53390  Percent of adults who engage in no leisure-tim...              NaN   \n",
              "53391  Percent of adults who engage in no leisure-tim...              NaN   \n",
              "\n",
              "      Data_Value_Type  Data_Value  Data_Value_Alt Data_Value_Footnote_Symbol  \\\n",
              "0               Value        32.0            32.0                        NaN   \n",
              "1               Value        32.3            32.3                        NaN   \n",
              "2               Value        31.8            31.8                        NaN   \n",
              "3               Value        33.6            33.6                        NaN   \n",
              "4               Value        32.8            32.8                        NaN   \n",
              "...               ...         ...             ...                        ...   \n",
              "53387           Value         NaN             NaN                          ~   \n",
              "53388           Value         NaN             NaN                          ~   \n",
              "53389           Value         NaN             NaN                          ~   \n",
              "53390           Value         NaN             NaN                          ~   \n",
              "53391           Value         NaN             NaN                          ~   \n",
              "\n",
              "                                     Data_Value_Footnote  \\\n",
              "0                                                    NaN   \n",
              "1                                                    NaN   \n",
              "2                                                    NaN   \n",
              "3                                                    NaN   \n",
              "4                                                    NaN   \n",
              "...                                                  ...   \n",
              "53387  Data not available because sample size is insu...   \n",
              "53388  Data not available because sample size is insu...   \n",
              "53389  Data not available because sample size is insu...   \n",
              "53390  Data not available because sample size is insu...   \n",
              "53391  Data not available because sample size is insu...   \n",
              "\n",
              "       Low_Confidence_Limit  High_Confidence_Limit   Sample_Size  Total  \\\n",
              "0                      30.5                    33.5       7304.0  Total   \n",
              "1                      29.9                    34.7       2581.0    NaN   \n",
              "2                      30.0                    33.6       4723.0    NaN   \n",
              "3                      29.9                    37.6       1153.0    NaN   \n",
              "4                      30.2                    35.6       2402.0    NaN   \n",
              "...                     ...                     ...          ...    ...   \n",
              "53387                   NaN                     NaN          NaN    NaN   \n",
              "53388                   NaN                     NaN          NaN    NaN   \n",
              "53389                   NaN                     NaN          NaN    NaN   \n",
              "53390                   NaN                     NaN          NaN    NaN   \n",
              "53391                   NaN                     NaN          NaN    NaN   \n",
              "\n",
              "      Age(years)              Education  Gender Income  \\\n",
              "0            NaN                    NaN     NaN    NaN   \n",
              "1            NaN                    NaN    Male    NaN   \n",
              "2            NaN                    NaN  Female    NaN   \n",
              "3            NaN  Less than high school     NaN    NaN   \n",
              "4            NaN   High school graduate     NaN    NaN   \n",
              "...          ...                    ...     ...    ...   \n",
              "53387        NaN                    NaN     NaN    NaN   \n",
              "53388        NaN                    NaN     NaN    NaN   \n",
              "53389        NaN                    NaN     NaN    NaN   \n",
              "53390        NaN                    NaN     NaN    NaN   \n",
              "53391        NaN                    NaN     NaN    NaN   \n",
              "\n",
              "                      Race/Ethnicity                              GeoLocation  \\\n",
              "0                                NaN  (32.84057112200048, -86.63186076199969)   \n",
              "1                                NaN  (32.84057112200048, -86.63186076199969)   \n",
              "2                                NaN  (32.84057112200048, -86.63186076199969)   \n",
              "3                                NaN  (32.84057112200048, -86.63186076199969)   \n",
              "4                                NaN  (32.84057112200048, -86.63186076199969)   \n",
              "...                              ...                                      ...   \n",
              "53387                          Asian                  (18.335765, -64.896335)   \n",
              "53388      Hawaiian/Pacific Islander                  (18.335765, -64.896335)   \n",
              "53389  American Indian/Alaska Native                  (18.335765, -64.896335)   \n",
              "53390                2 or more races                  (18.335765, -64.896335)   \n",
              "53391                          Other                  (18.335765, -64.896335)   \n",
              "\n",
              "      ClassID TopicID QuestionID DataValueTypeID  LocationID  \\\n",
              "0         OWS    OWS1       Q036           VALUE           1   \n",
              "1         OWS    OWS1       Q036           VALUE           1   \n",
              "2         OWS    OWS1       Q036           VALUE           1   \n",
              "3         OWS    OWS1       Q036           VALUE           1   \n",
              "4         OWS    OWS1       Q036           VALUE           1   \n",
              "...       ...     ...        ...             ...         ...   \n",
              "53387      PA     PA1       Q047           VALUE          78   \n",
              "53388      PA     PA1       Q047           VALUE          78   \n",
              "53389      PA     PA1       Q047           VALUE          78   \n",
              "53390      PA     PA1       Q047           VALUE          78   \n",
              "53391      PA     PA1       Q047           VALUE          78   \n",
              "\n",
              "      StratificationCategory1                Stratification1  \\\n",
              "0                       Total                          Total   \n",
              "1                      Gender                           Male   \n",
              "2                      Gender                         Female   \n",
              "3                   Education          Less than high school   \n",
              "4                   Education           High school graduate   \n",
              "...                       ...                            ...   \n",
              "53387          Race/Ethnicity                          Asian   \n",
              "53388          Race/Ethnicity      Hawaiian/Pacific Islander   \n",
              "53389          Race/Ethnicity  American Indian/Alaska Native   \n",
              "53390          Race/Ethnicity                2 or more races   \n",
              "53391          Race/Ethnicity                          Other   \n",
              "\n",
              "      StratificationCategoryId1 StratificationID1  \n",
              "0                           OVR           OVERALL  \n",
              "1                           GEN              MALE  \n",
              "2                           GEN            FEMALE  \n",
              "3                           EDU             EDUHS  \n",
              "4                           EDU         EDUHSGRAD  \n",
              "...                         ...               ...  \n",
              "53387                      RACE           RACEASN  \n",
              "53388                      RACE           RACEHPI  \n",
              "53389                      RACE           RACENAA  \n",
              "53390                      RACE         RACE2PLUS  \n",
              "53391                      RACE           RACEOTH  \n",
              "\n",
              "[53392 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv(\n",
        "    'Nutrition__Physical_Activity__and_Obesity_-_Behavioral_Risk_Factor_Surveillance_System.csv')\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW9yjrdIKdFf"
      },
      "outputs": [],
      "source": [
        "##PASSO: 6 modelos selecionados para otimização: ['Linear Regression', 'Gradient Boosting', 'Random Forest']\n",
        "\n",
        "# Configurações iniciais\n",
        "warnings.filterwarnings('ignore')\n",
        "#pd.set_option('display.max_columns', 50)\n",
        "sns.set(style='whitegrid', palette='pastel')\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "def clean_column_names(df):\n",
        "    \"\"\"Padroniza nomes de colunas\"\"\"\n",
        "    df.columns = [re.sub(r'[^a-zA-Z0-9_]', '', col.lower().replace(' ', '_'))\n",
        "                 for col in df.columns]\n",
        "    return df\n",
        "\n",
        "def basic_data_cleaning(df):\n",
        "    \"\"\"Realiza limpeza básica dos dados\"\"\"\n",
        "    df = clean_column_names(df)\n",
        "\n",
        "    # Identifica coluna alvo\n",
        "    target_candidates = ['datavalue', 'value', 'obesityrate', 'prevalence', 'rate']\n",
        "    for col in target_candidates:\n",
        "        if col in df.columns:\n",
        "            df.rename(columns={col: 'obesity_rate'}, inplace=True)\n",
        "            break\n",
        "    else:\n",
        "        # Se não encontrar, assume a primeira coluna numérica como alvo\n",
        "        num_cols = df.select_dtypes(include=np.number).columns\n",
        "        if len(num_cols) > 0:\n",
        "            df.rename(columns={num_cols[0]: 'obesity_rate'}, inplace=True)\n",
        "        else:\n",
        "            # Se não houver colunas numéricas, cria uma coluna vazia\n",
        "            df['obesity_rate'] = np.nan\n",
        "\n",
        "    # Remove colunas completamente vazias\n",
        "    df.dropna(axis=1, how='all', inplace=True)\n",
        "\n",
        "    # Remove linhas duplicadas\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    return df\n",
        "\n",
        "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Pipeline personalizado para pré-processamento\"\"\"\n",
        "    def _init_(self, date_columns=None, categorical_threshold=15):\n",
        "        self.date_columns = date_columns\n",
        "        self.categorical_threshold = categorical_threshold\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Tratamento de datas\n",
        "        if self.date_columns:\n",
        "            for col in self.date_columns:\n",
        "                if col in X.columns:\n",
        "                    try:\n",
        "                        X[col] = pd.to_datetime(X[col], errors='coerce')\n",
        "                        X[f'{col}_year'] = X[col].dt.year.fillna(X[col].dt.year.median())\n",
        "                        X[f'{col}_month'] = X[col].dt.month.fillna(X[col].dt.month.median())\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao processar coluna de data {col}: {str(e)}\")\n",
        "\n",
        "        # Conversão de tipos\n",
        "        for col in X.select_dtypes(include='object').columns:\n",
        "            # Tenta converter para numérico\n",
        "            try:\n",
        "                X[col] = pd.to_numeric(X[col], errors='ignore')\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Identifica colunas categóricas com baixa cardinalidade\n",
        "            unique_count = X[col].nunique()\n",
        "            if 1 < unique_count < self.categorical_threshold:\n",
        "                X[col] = X[col].astype('category')\n",
        "\n",
        "        # Tratamento de outliers para colunas numéricas\n",
        "        num_cols = X.select_dtypes(include=np.number).columns\n",
        "        for col in num_cols:\n",
        "            # Ignora colunas com baixa variância\n",
        "            if X[col].nunique() > 1:\n",
        "                q1 = X[col].quantile(0.05)\n",
        "                q3 = X[col].quantile(0.95)\n",
        "                X[col] = np.clip(X[col], q1, q3)\n",
        "\n",
        "        return X\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"Cria novas features a partir dos dados existentes\"\"\"\n",
        "    if df is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        df = df.copy()\n",
        "\n",
        "        # 1. Conversão segura de colunas de ano\n",
        "        for col in ['yearstart', 'yearend']:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        # 2. Média de anos (depois da conversão)\n",
        "        if 'yearstart' in df.columns and 'yearend' in df.columns:\n",
        "            df['year_avg'] = (df['yearstart'] + df['yearend']) / 2\n",
        "\n",
        "        # 3. Mapeamento de regiões\n",
        "        if 'locationdesc' in df.columns:\n",
        "            regions = {\n",
        "                'northeast': ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire',\n",
        "                              'Rhode Island', 'Vermont', 'New Jersey', 'New York', 'Pennsylvania'],\n",
        "                'midwest': ['Illinois', 'Indiana', 'Michigan', 'Ohio', 'Wisconsin',\n",
        "                            'Iowa', 'Kansas', 'Minnesota', 'Missouri', 'Nebraska', 'North Dakota', 'South Dakota'],\n",
        "                'south': ['Delaware', 'Florida', 'Georgia', 'Maryland', 'North Carolina',\n",
        "                          'South Carolina', 'Virginia', 'District of Columbia', 'West Virginia',\n",
        "                          'Alabama', 'Kentucky', 'Mississippi', 'Tennessee', 'Arkansas', 'Louisiana', 'Oklahoma', 'Texas'],\n",
        "                'west': ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'New Mexico', 'Utah', 'Wyoming',\n",
        "                         'Alaska', 'California', 'Hawaii', 'Oregon', 'Washington']\n",
        "            }\n",
        "\n",
        "            def map_region(location):\n",
        "                for region, states in regions.items():\n",
        "                    if location in states:\n",
        "                        return region\n",
        "                return 'other'\n",
        "\n",
        "            df['region'] = df['locationdesc'].apply(map_region)\n",
        "\n",
        "        # 4. Preenchimento de valores ausentes nas colunas temporais\n",
        "        for col in ['yearstart', 'yearend', 'year_avg']:\n",
        "            if col in df.columns:\n",
        "                if df[col].isnull().sum() > 0:\n",
        "                    median_val = df[col].median()\n",
        "                    df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "        # 5. Agrupamento de categorias raras\n",
        "        if 'stratificationcategory1' in df.columns:\n",
        "            category_counts = df['stratificationcategory1'].value_counts()\n",
        "            rare_categories = category_counts[category_counts < 100].index\n",
        "            df['strat_group'] = df['stratificationcategory1'].replace(rare_categories, 'Other')\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na engenharia de features: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ae3mqBffMEM"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# PASSO: 3 Visualização de Dados\n",
        "# ====================================================\n",
        "def create_diagnostic_plots(df):\n",
        "    \"\"\"Gera visualizações diagnósticas dos dados\"\"\"\n",
        "    if df is None or 'obesity_rate' not in df.columns:\n",
        "        print(\"Dados inválidos ou coluna 'obesity_rate' não encontrada para plotagem\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Conversões seguras\n",
        "        df['obesity_rate'] = pd.to_numeric(df['obesity_rate'], errors='coerce')\n",
        "        if 'yearstart' in df.columns:\n",
        "            df['yearstart'] = pd.to_numeric(df['yearstart'], errors='coerce')\n",
        "\n",
        "        plt.figure(figsize=(18, 14))\n",
        "\n",
        "        # 1. Distribuição da variável alvo\n",
        "        plt.subplot(2, 2, 1)\n",
        "        sns.histplot(df['obesity_rate'].dropna(), kde=True, bins=20)\n",
        "        plt.title('Distribuição da Taxa de Obesidade', fontsize=14)\n",
        "        plt.xlabel('Taxa de Obesidade (%)', fontsize=12)\n",
        "        plt.ylabel('Frequência', fontsize=12)\n",
        "\n",
        "        # 2. Evolução temporal\n",
        "        plt.subplot(2, 2, 2)\n",
        "        if 'yearstart' in df.columns and df['yearstart'].nunique() > 1:\n",
        "            yearly_data = df.groupby('yearstart')['obesity_rate'].agg(['mean', 'median', 'std']).dropna()\n",
        "            plt.plot(yearly_data.index, yearly_data['median'], marker='o', linestyle='-', color='b')\n",
        "            plt.fill_between(\n",
        "                yearly_data.index,\n",
        "                yearly_data['median'] - yearly_data['std'],\n",
        "                yearly_data['median'] + yearly_data['std'],\n",
        "                alpha=0.2, color='b'\n",
        "            )\n",
        "            plt.title('Evolução Anual da Obesidade', fontsize=14)\n",
        "            plt.xlabel('Ano', fontsize=12)\n",
        "            plt.ylabel('Taxa de Obesidade (Mediana)', fontsize=12)\n",
        "            plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Dados insuficientes para análise temporal',\n",
        "                     horizontalalignment='center', verticalalignment='center')\n",
        "            plt.title('Evolução Anual da Obesidade', fontsize=14)\n",
        "\n",
        "        # 3. Obesidade por categoria\n",
        "        plt.subplot(2, 2, 3)\n",
        "        categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "        cat_col = None\n",
        "        for col in categorical_cols:\n",
        "            if col != 'locationdesc' and 1 < df[col].nunique() <= 20:\n",
        "                cat_col = col\n",
        "                break\n",
        "        if cat_col is None and len(categorical_cols) > 0:\n",
        "            cat_col = categorical_cols[0]\n",
        "\n",
        "        if cat_col:\n",
        "            if df[cat_col].nunique() > 10:\n",
        "                top_cats = df[cat_col].value_counts().nlargest(10).index\n",
        "                filtered_df = df[df[cat_col].isin(top_cats)]\n",
        "            else:\n",
        "                filtered_df = df\n",
        "\n",
        "            if not filtered_df.empty and filtered_df['obesity_rate'].notnull().any():\n",
        "                sns.boxplot(\n",
        "                    x=cat_col,\n",
        "                    y='obesity_rate',\n",
        "                    data=filtered_df.dropna(subset=['obesity_rate', cat_col])\n",
        "                )\n",
        "                plt.xticks(rotation=45, ha='right')\n",
        "                plt.title(f'Obesidade por {cat_col}', fontsize=14)\n",
        "                plt.xlabel(cat_col, fontsize=12)\n",
        "                plt.ylabel('Taxa de Obesidade', fontsize=12)\n",
        "            else:\n",
        "                plt.text(0.5, 0.5, 'Dados insuficientes para plotar',\n",
        "                         horizontalalignment='center', verticalalignment='center')\n",
        "                plt.title(f'Obesidade por {cat_col}', fontsize=14)\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Nenhuma coluna categórica disponível',\n",
        "                     horizontalalignment='center', verticalalignment='center')\n",
        "            plt.title('Obesidade por Categoria', fontsize=14)\n",
        "\n",
        "        # 4. Matriz de correlação\n",
        "        plt.subplot(2, 2, 4)\n",
        "        numeric_df = df.select_dtypes(include=np.number)\n",
        "        if numeric_df.shape[1] > 1:\n",
        "            corr_matrix = numeric_df.corr()\n",
        "            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "            sns.heatmap(\n",
        "                corr_matrix,\n",
        "                mask=mask,\n",
        "                annot=True,\n",
        "                fmt=\".2f\",\n",
        "                cmap='coolwarm',\n",
        "                vmin=-1,\n",
        "                vmax=1,\n",
        "                annot_kws={\"size\": 8}\n",
        "            )\n",
        "            plt.title('Matriz de Correlação', fontsize=14)\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Dados numéricos insuficientes para matriz de correlação',\n",
        "                     horizontalalignment='center', verticalalignment='center')\n",
        "            plt.title('Matriz de Correlação', fontsize=14)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('analise_obesidade_diagnostico.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"✅ Visualizações salvas como 'analise_obesidade_diagnostico.png'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao gerar visualizações: {str(e)}\")\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK7wiTqAIIuF"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# PASSO: 4 Modelagem Preditiva\n",
        "# ====================================================\n",
        "def build_model_pipeline(X_train):\n",
        "    \"\"\"Constrói pipeline de modelagem dinâmico baseado nos dados\"\"\"\n",
        "    # Identifica features\n",
        "    features = [col for col in X_train.columns]\n",
        "\n",
        "    # Separa features numéricas e categóricas\n",
        "    numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
        "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    # Transformers\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    # Pré-processador\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Modelo base\n",
        "    model = GradientBoostingRegressor(\n",
        "        random_state=42,\n",
        "        n_estimators=150,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        min_samples_split=10\n",
        "    )\n",
        "\n",
        "    # Pipeline completo\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "    return pipeline, numeric_features, categorical_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZYWjgaAIPKm"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import traceback\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from scipy.stats import randint, uniform\n",
        "import joblib\n",
        "\n",
        "# ====================================================\n",
        "# PASSO: 5 Fluxo Principal de Execução\n",
        "# ====================================================\n",
        "def basic_data_cleaning(df):\n",
        "    \"\"\"Realiza passos básicos de limpeza de dados.\"\"\"\n",
        "    print(\"Realizando limpeza básica de dados...\")\n",
        "    df.columns = [re.sub(r'[^a-zA-Z0-9_]', '', col.lower().replace(' ', '_'))\n",
        "                 for col in df.columns]\n",
        "\n",
        "    target_candidates = ['datavalue', 'value', 'obesityrate', 'prevalence', 'rate']\n",
        "    for col in target_candidates:\n",
        "        if col in df.columns:\n",
        "            df.rename(columns={col: 'obesity_rate'}, inplace=True)\n",
        "            break\n",
        "    else:\n",
        "        num_cols = df.select_dtypes(include=np.number).columns\n",
        "        if len(num_cols) > 0:\n",
        "            df.rename(columns={num_cols[0]: 'obesity_rate'}, inplace=True)\n",
        "        else:\n",
        "            df['obesity_rate'] = np.nan\n",
        "\n",
        "    threshold = len(df) * 0.5\n",
        "    df_cleaned = df.dropna(axis=1, thresh=threshold)\n",
        "    print(f\"Colunas originais: {df.shape[1]}, Colunas após limpeza: {df_cleaned.shape[1]}\")\n",
        "    return df_cleaned\n",
        "\n",
        "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Transformer customizado para pré-processamento de dados.\"\"\"\n",
        "    def __init__(self, date_columns=None, categorical_threshold=20):\n",
        "        self.date_columns = date_columns or []\n",
        "        self.categorical_threshold = categorical_threshold\n",
        "        self.categorical_features = None\n",
        "        self.numeric_features = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        self.numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        print(\"Realizando pré-processamento de dados...\")\n",
        "        X_processed = X.copy()\n",
        "\n",
        "        for col in self.date_columns:\n",
        "            if col in X_processed.columns:\n",
        "                try:\n",
        "                    X_processed[col] = pd.to_datetime(X_processed[col], errors='coerce')\n",
        "                    X_processed[col + '_year'] = X_processed[col].dt.year\n",
        "                    X_processed = X_processed.drop(columns=[col])\n",
        "                    print(f\"Coluna de data processada: {col}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Não foi possível processar a coluna de data {col}: {e}\")\n",
        "\n",
        "        for col in self.categorical_features:\n",
        "            if col in X_processed.columns:\n",
        "                if X_processed[col].nunique() > self.categorical_threshold:\n",
        "                    print(f\"Aviso: A coluna categórica '{col}' tem muitos valores únicos ({X_processed[col].nunique()}).\")\n",
        "\n",
        "        num_cols = X_processed.select_dtypes(include=np.number).columns\n",
        "        for col in num_cols:\n",
        "            if X_processed[col].nunique() > 1:\n",
        "                q1 = X_processed[col].quantile(0.05)\n",
        "                q3 = X_processed[col].quantile(0.95)\n",
        "                X_processed[col] = np.clip(X_processed[col], q1, q3)\n",
        "\n",
        "        print(\"Pré-processamento concluído.\")\n",
        "        return X_processed\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"Realiza engenharia de features.\"\"\"\n",
        "    print(\"Realizando engenharia de features...\")\n",
        "    df_engineered = df.copy()\n",
        "\n",
        "    if 'yearstart_year' in df_engineered.columns and 'yearend_year' in df_engineered.columns:\n",
        "        df_engineered['year_difference'] = df_engineered['yearend_year'] - df_engineered['yearstart_year']\n",
        "        print(\"Criada feature 'year_difference'.\")\n",
        "\n",
        "    # Remover qualquer feature que possa conter a variável alvo\n",
        "    forbidden_features = ['obesity_rate', 'data_value', 'value', 'rate', 'prevalence']\n",
        "    for col in forbidden_features:\n",
        "        if col in df_engineered.columns:\n",
        "            print(f\"⚠️ Removendo possível vazamento: {col}\")\n",
        "            df_engineered = df_engineered.drop(columns=[col])\n",
        "\n",
        "    print(\"Engenharia de features concluída.\")\n",
        "    return df_engineered\n",
        "\n",
        "def compare_models(X_train, y_train, X_test, y_test, preprocessor_pipe, sample_size=5000):\n",
        "    \"\"\"Compara a performance de diferentes modelos de regressão com amostragem.\"\"\"\n",
        "    print(\"\\nComparando diferentes modelos com amostra de dados...\")\n",
        "\n",
        "    # Amostrar dados para acelerar o processo\n",
        "    if len(X_train) > sample_size:\n",
        "        X_train_sample = X_train.sample(sample_size, random_state=42)\n",
        "        y_train_sample = y_train.loc[X_train_sample.index]\n",
        "        print(f\"Usando amostra de {sample_size} registros para comparação de modelos\")\n",
        "    else:\n",
        "        X_train_sample = X_train\n",
        "        y_train_sample = y_train\n",
        "        print(\"Usando conjunto completo de treino para comparação de modelos\")\n",
        "\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(n_jobs=-1),\n",
        "        'Random Forest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
        "        'ElasticNet': ElasticNet(random_state=42),\n",
        "        'KNeighbors Regressor': KNeighborsRegressor(n_jobs=-1)\n",
        "    }\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            pipeline = Pipeline(steps=[('preprocessor', preprocessor_pipe),\n",
        "                                      ('regressor', model)])\n",
        "            pipeline.fit(X_train_sample, y_train_sample)\n",
        "            y_pred = pipeline.predict(X_test)\n",
        "\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            train_time = time.time() - start_time\n",
        "\n",
        "            # Formatar resultados para mostrar números reais\n",
        "            results.append({\n",
        "                'Modelo': name,\n",
        "                'RMSE': f\"{rmse:.4f}\",\n",
        "                'R²': f\"{r2:.4f}\",\n",
        "                'MAE': f\"{mae:.4f}\",\n",
        "                'Tempo Treino (s)': f\"{train_time:.2f}\"\n",
        "            })\n",
        "            print(f\"  - {name}: RMSE={rmse:.4f}, R²={r2:.4f}, MAE={mae:.4f}, Tempo={train_time:.2f}s\")\n",
        "        except Exception as e:\n",
        "            print(f\"  - Erro ao treinar/avaliar {name}: {str(e)}\")\n",
        "            results.append({\n",
        "                'Modelo': name,\n",
        "                'RMSE': \"Erro\",\n",
        "                'R²': \"Erro\",\n",
        "                'MAE': \"Erro\",\n",
        "                'Tempo Treino (s)': \"Erro\"\n",
        "            })\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "    print(\"\\nResultados da comparação de modelos:\")\n",
        "    print(results_df)\n",
        "\n",
        "    try:\n",
        "        # Converter para numérico para plotagem\n",
        "        plot_df = results_df.copy()\n",
        "        plot_df['RMSE'] = pd.to_numeric(plot_df['RMSE'], errors='coerce')\n",
        "        plot_df['R²'] = pd.to_numeric(plot_df['R²'], errors='coerce')\n",
        "        plot_df['MAE'] = pd.to_numeric(plot_df['MAE'], errors='coerce')\n",
        "        plot_df['Tempo Treino (s)'] = pd.to_numeric(plot_df['Tempo Treino (s)'], errors='coerce')\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.subplot(2, 2, 1)\n",
        "        sns.barplot(x='RMSE', y='Modelo', data=plot_df, palette='viridis')\n",
        "        plt.title('Comparação de RMSE')\n",
        "        plt.xlabel('RMSE')\n",
        "        plt.subplot(2, 2, 2)\n",
        "        sns.barplot(x='R²', y='Modelo', data=plot_df, palette='viridis')\n",
        "        plt.title('Comparação de R²')\n",
        "        plt.xlabel('Coeficiente de Determinação (R²)')\n",
        "        plt.subplot(2, 2, 3)\n",
        "        sns.barplot(x='MAE', y='Modelo', data=plot_df, palette='viridis')\n",
        "        plt.title('Comparação de MAE')\n",
        "        plt.xlabel('Erro Absoluto Médio (MAE)')\n",
        "        plt.subplot(2, 2, 4)\n",
        "        sns.barplot(x='Tempo Treino (s)', y='Modelo', data=plot_df, palette='viridis')\n",
        "        plt.title('Tempo de Treinamento')\n",
        "        plt.xlabel('Segundos')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('comparacao_modelos.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar gráficos: {str(e)}\")\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def optimize_hyperparameters(base_model, param_grid, preprocessor_pipe, X_train, y_train):\n",
        "    \"\"\"Otimiza hiperparâmetros para um dado modelo usando RandomizedSearchCV com configuração eficiente.\"\"\"\n",
        "    model_name = type(base_model).__name__\n",
        "    print(f\"Otimizando hiperparâmetros para {model_name}...\")\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor_pipe),\n",
        "                               ('regressor', base_model)])\n",
        "\n",
        "    if not param_grid and model_name != 'LinearRegression':\n",
        "        print(\"Nenhuma grade de parâmetros fornecida para otimização. Usando o modelo base.\")\n",
        "        return pipeline.fit(X_train, y_train), {}\n",
        "    elif model_name == 'LinearRegression':\n",
        "        print(\"Linear Regression não requer otimização de hiperparâmetros. Usando o modelo base.\")\n",
        "        return pipeline.fit(X_train, y_train), {}\n",
        "\n",
        "    try:\n",
        "        # Configuração otimizada para velocidade\n",
        "        random_search = RandomizedSearchCV(\n",
        "            pipeline,\n",
        "            param_grid,\n",
        "            n_iter=10,  # Reduzido para 10 iterações\n",
        "            cv=KFold(n_splits=3, shuffle=True, random_state=42),  # Reduzido para 3 folds\n",
        "            scoring='neg_root_mean_squared_error',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,  # Usar todos os núcleos disponíveis\n",
        "            verbose=1\n",
        "        )\n",
        "        random_search.fit(X_train, y_train)\n",
        "        print(f\"Melhores parâmetros encontrados: {random_search.best_params_}\")\n",
        "        print(f\"Melhor RMSE de validação cruzada: {-random_search.best_score_:.4f}\")\n",
        "        return random_search.best_estimator_, random_search.best_params_\n",
        "    except Exception as e:\n",
        "        print(f\"Erro durante a otimização de hiperparâmetros: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return pipeline.fit(X_train, y_train), {}\n",
        "\n",
        "def compare_optimized_models(best_models, X_test, y_test):\n",
        "    \"\"\"Compara a performance de modelos otimizados.\"\"\"\n",
        "    print(\"\\nComparando modelos otimizados...\")\n",
        "    results = []\n",
        "    for name, model in best_models.items():\n",
        "        try:\n",
        "            y_pred = model.predict(X_test)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "            # Formatar resultados para mostrar números reais\n",
        "            results.append({\n",
        "                'Modelo': name,\n",
        "                'RMSE': f\"{rmse:.4f}\",\n",
        "                'R²': f\"{r2:.4f}\",\n",
        "                'MAE': f\"{mae:.4f}\"\n",
        "            })\n",
        "            print(f\"  - {name}: RMSE={rmse:.4f}, R²={r2:.4f}, MAE={mae:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  - Erro ao avaliar o modelo otimizado {name}: {str(e)}\")\n",
        "            results.append({\n",
        "                'Modelo': name,\n",
        "                'RMSE': \"Erro\",\n",
        "                'R²': \"Erro\",\n",
        "                'MAE': \"Erro\"\n",
        "            })\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "    print(\"\\nResultados da comparação de modelos otimizados:\")\n",
        "    print(results_df)\n",
        "\n",
        "    try:\n",
        "        # Converter para numérico para plotagem\n",
        "        plot_df = results_df.copy()\n",
        "        plot_df['RMSE'] = pd.to_numeric(plot_df['RMSE'], errors='coerce')\n",
        "        plot_df['R²'] = pd.to_numeric(plot_df['R²'], errors='coerce')\n",
        "\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.barplot(x='RMSE', y='Modelo', data=plot_df, palette='viridis')\n",
        "        plt.title('Comparação de RMSE (Modelos Otimizados)')\n",
        "        plt.xlabel('RMSE')\n",
        "        plt.subplot(1, 2, 2)\n",
        "        sns.barplot(x='R²', y='Modelo', data=plot_df, palette='viridis')\n",
        "        plt.title('Comparação de R² (Modelos Otimizados)')\n",
        "        plt.xlabel('Coeficiente de Determinação (R²)')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('comparacao_modelos_otimizados.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar gráficos: {str(e)}\")\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def create_diagnostic_plots(df):\n",
        "    \"\"\"Gera visualizações diagnósticas dos dados\"\"\"\n",
        "    if df is None or 'obesity_rate' not in df.columns:\n",
        "        print(\"Dados inválidos ou coluna 'obesity_rate' não encontrada para plotagem\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        df['obesity_rate'] = pd.to_numeric(df['obesity_rate'], errors='coerce')  # Corrigido typo aqui\n",
        "        year_col = None\n",
        "        if 'yearstart_year' in df.columns:\n",
        "            year_col = 'yearstart_year'\n",
        "        elif 'yearend_year' in df.columns:\n",
        "            year_col = 'yearend_year'\n",
        "        elif 'yearstart' in df.columns:\n",
        "            year_col = 'yearstart'\n",
        "\n",
        "        plt.figure(figsize=(18, 14))\n",
        "        plt.subplot(2, 2, 1)\n",
        "        sns.histplot(df['obesity_rate'].dropna(), kde=True, bins=20)\n",
        "        plt.title('Distribuição da Taxa de Obesidade')\n",
        "        plt.xlabel('Taxa de Obesidade (%)')\n",
        "        plt.ylabel('Frequência')\n",
        "\n",
        "        plt.subplot(2, 2, 2)\n",
        "        if year_col and df[year_col].nunique() > 1:\n",
        "            df[year_col] = pd.to_numeric(df[year_col], errors='coerce')\n",
        "            yearly_data = df.groupby(year_col)['obesity_rate'].agg(['mean', 'median', 'std']).dropna()\n",
        "            plt.plot(yearly_data.index, yearly_data['median'], marker='o')\n",
        "            plt.fill_between(yearly_data.index,\n",
        "                             yearly_data['median'] - yearly_data['std'],\n",
        "                             yearly_data['median'] + yearly_data['std'],\n",
        "                             alpha=0.2)\n",
        "            plt.title('Evolução Anual da Obesidade')\n",
        "            plt.xlabel('Ano')\n",
        "            plt.ylabel('Taxa de Obesidade (Mediana)')\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Dados insuficientes para análise temporal', ha='center')\n",
        "            plt.title('Evolução Anual da Obesidade')\n",
        "\n",
        "        # CORREÇÃO PRINCIPAL: Identação correta deste bloco\n",
        "        plt.subplot(2, 2, 3)\n",
        "        categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "        cat_col = None\n",
        "        for col in categorical_cols:\n",
        "            if col != 'locationdesc' and 1 < df[col].nunique() <= 20:\n",
        "                cat_col = col\n",
        "                break\n",
        "\n",
        "        # Identação corrigida abaixo\n",
        "        if cat_col is None and len(categorical_cols) > 0:\n",
        "            for col in categorical_cols:\n",
        "                if 1 < df[col].nunique() <= 30:\n",
        "                    cat_col = col\n",
        "                    break\n",
        "\n",
        "        if cat_col:\n",
        "            if df[cat_col].nunique() > 10:\n",
        "                top_cats = df[cat_col].value_counts().nlargest(10).index\n",
        "                filtered_df = df[df[cat_col].isin(top_cats)]\n",
        "            else:\n",
        "                filtered_df = df\n",
        "\n",
        "            if not filtered_df.empty and filtered_df['obesity_rate'].notnull().any():\n",
        "                sns.boxplot(\n",
        "                    x=cat_col,\n",
        "                    y='obesity_rate',\n",
        "                    data=filtered_df.dropna(subset=['obesity_rate', cat_col])\n",
        "                )\n",
        "                plt.xticks(rotation=45, ha='right')\n",
        "                plt.title(f'Obesidade por {cat_col}')\n",
        "                plt.xlabel(cat_col)\n",
        "                plt.ylabel('Taxa de Obesidade')\n",
        "            else:\n",
        "                plt.text(0.5, 0.5, 'Dados insuficientes para plotar', ha='center')\n",
        "                plt.title(f'Obesidade por {cat_col}')\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Nenhuma coluna categórica disponível', ha='center')\n",
        "            plt.title('Obesidade por Categoria')\n",
        "\n",
        "        plt.subplot(2, 2, 4)\n",
        "        numeric_df = df.select_dtypes(include=np.number)\n",
        "        if numeric_df.shape[1] > 1:\n",
        "            corr_matrix = numeric_df.corr()\n",
        "            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "            sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
        "                        vmin=-1, vmax=1, annot_kws={\"size\":8})\n",
        "            plt.title('Matriz de Correlação')\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Dados numéricos insuficientes para matriz de correlação', ha='center')\n",
        "            plt.title('Matriz de Correlação')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('analise_obesidade_diagnostico.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"✅ Visualizações salvas como 'analise_obesidade_diagnostico.png'\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao gerar visualizações: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def build_model_pipeline(X_train):\n",
        "    \"\"\"Constrói pipeline de modelagem dinâmico baseado nos dados\"\"\"\n",
        "    numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
        "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "    model = GradientBoostingRegressor(\n",
        "        random_state=42,\n",
        "        n_estimators=150,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        min_samples_split=10\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "    return pipeline, numeric_features, categorical_features\n",
        "\n",
        "def main(df):\n",
        "    \"\"\"Fluxo principal de execução otimizado para velocidade\"\"\"\n",
        "    try:\n",
        "        # 1. Limpeza básica de dados\n",
        "        df_cleaned = basic_data_cleaning(df)\n",
        "\n",
        "        # 2. Identificar colunas de data automaticamente\n",
        "        date_cols = [col for col in df_cleaned.columns\n",
        "                     if 'date' in col.lower() or 'year' in col.lower() or 'time' in col.lower()]\n",
        "        print(f\"Colunas de data identificadas: {date_cols}\")\n",
        "\n",
        "        # 3. Pré-processamento\n",
        "        preprocessor = DataPreprocessor(date_columns=date_cols, categorical_threshold=20)\n",
        "        X = df_cleaned.drop(columns=['obesity_rate'], errors='ignore')\n",
        "        y = df_cleaned['obesity_rate']\n",
        "\n",
        "        # Converter para numérico se necessário\n",
        "        if not pd.api.types.is_numeric_dtype(y):\n",
        "            y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "        # 4. Engenharia de features\n",
        "        X_preprocessed = preprocessor.fit_transform(X)\n",
        "        X_engineered = feature_engineering(X_preprocessed)\n",
        "\n",
        "        # Verificar vazamento de dados\n",
        "        if 'obesity_rate' in X_engineered.columns:\n",
        "            print(\"⚠️ ATENÇÃO: Variável alvo encontrada nas features. Removendo...\")\n",
        "            X_engineered = X_engineered.drop(columns=['obesity_rate'])\n",
        "\n",
        "        # 5. Dividir dados (usando amostra se conjunto for muito grande)\n",
        "        if len(X_engineered) > 10000:\n",
        "            sample_size = min(10000, len(X_engineered))\n",
        "            X_sample = X_engineered.sample(sample_size, random_state=42)\n",
        "            y_sample = y.loc[X_sample.index]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "            print(f\"Usando amostra de {sample_size} registros para modelagem\")\n",
        "        else:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_engineered, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # 6. Construir pipeline de modelagem\n",
        "        model_pipeline, numeric_features, categorical_features = build_model_pipeline(X_train)\n",
        "        preprocessor_pipe = model_pipeline.named_steps['preprocessor']\n",
        "\n",
        "        # 7. Comparar modelos com amostra\n",
        "        results_df = compare_models(X_train, y_train, X_test, y_test, preprocessor_pipe)\n",
        "\n",
        "        # 8. Otimizar apenas os 2 melhores modelos\n",
        "        top_models = results_df.head(2)['Modelo'].tolist()\n",
        "        print(f\"\\nOtimizando os melhores modelos: {top_models}\")\n",
        "\n",
        "        # Grades de parâmetros simplificadas\n",
        "        param_grids = {\n",
        "            'Random Forest': {\n",
        "                'regressor__n_estimators': randint(50, 200),\n",
        "                'regressor__max_depth': [None, 5, 10],\n",
        "                'regressor__min_samples_split': randint(2, 10)\n",
        "            },\n",
        "            'Gradient Boosting': {\n",
        "                'regressor__n_estimators': randint(50, 150),\n",
        "                'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
        "                'regressor__max_depth': randint(3, 8)\n",
        "            },\n",
        "            'Linear Regression': {}  # Sem otimização\n",
        "        }\n",
        "\n",
        "        best_models = {}\n",
        "        for model_name in top_models:\n",
        "            if model_name == 'Random Forest':\n",
        "                base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "            elif model_name == 'Gradient Boosting':\n",
        "                base_model = GradientBoostingRegressor(random_state=42)\n",
        "            elif model_name == 'Linear Regression':\n",
        "                base_model = LinearRegression(n_jobs=-1)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            best_model, best_params = optimize_hyperparameters(\n",
        "                base_model,\n",
        "                param_grids.get(model_name, {}),\n",
        "                preprocessor_pipe,\n",
        "                X_train,\n",
        "                y_train\n",
        "            )\n",
        "            best_models[model_name] = best_model\n",
        "\n",
        "        # 9. Comparar modelos otimizados\n",
        "        optimized_results = compare_optimized_models(best_models, X_test, y_test)\n",
        "\n",
        "        # 10. Salvar o melhor modelo\n",
        "        best_model_name = optimized_results.iloc[0]['Modelo']\n",
        "        best_model = best_models[best_model_name]\n",
        "        joblib.dump(best_model, 'best_model.pkl')\n",
        "        print(f\"Melhor modelo ({best_model_name}) salvo como 'best_model.pkl'\")\n",
        "\n",
        "        # 11. Visualizações diagnósticas\n",
        "        create_diagnostic_plots(df_cleaned)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PROCESSO CONCLUÍDO COM SUCESSO!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"❌ ERRO NO PROCESSO PRINCIPAL\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Erro: {str(e)}\")\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD9z6OGrIMV2"
      },
      "outputs": [],
      "source": [
        "# Definindo as funções ausentes: basic_data_cleaning, DataPreprocessor, feature_engineering, compare_models, e optimize_hyperparameters\n",
        "\n",
        "def basic_data_cleaning(df):\n",
        "    \"\"\"Realiza passos básicos de limpeza de dados.\"\"\"\n",
        "    print(\"Realizando limpeza básica de dados...\")\n",
        "    # Exemplo de limpeza: remover colunas com muitos valores ausentes\n",
        "    threshold = len(df) * 0.5\n",
        "    df_cleaned = df.dropna(axis=1, thresh=threshold)\n",
        "    print(f\"Colunas originais: {df.shape[1]}, Colunas após limpeza: {df_cleaned.shape[1]}\")\n",
        "    return df_cleaned\n",
        "\n",
        "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Transformer customizado para pré-processamento de dados.\"\"\"\n",
        "    def __init__(self, date_columns=None, categorical_threshold=20):\n",
        "        self.date_columns = date_columns\n",
        "        self.categorical_threshold = categorical_threshold\n",
        "        self.categorical_features = None\n",
        "        self.numeric_features = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Identifica features categóricas e numéricas\n",
        "        self.categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        self.numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        print(\"Realizando pré-processamento de dados...\")\n",
        "        X_processed = X.copy()\n",
        "\n",
        "        # Lida com colunas de data se especificadas\n",
        "        if self.date_columns:\n",
        "            for col in self.date_columns:\n",
        "                if col in X_processed.columns:\n",
        "                    try:\n",
        "                        # Converte para objetos datetime, forçando erros\n",
        "                        X_processed[col] = pd.to_datetime(X_processed[col], errors='coerce')\n",
        "                        # Exemplo de extração de feature: ano\n",
        "                        X_processed[col + '_year'] = X_processed[col].dt.year\n",
        "                        # Remove a coluna de data original\n",
        "                        X_processed = X_processed.drop(columns=[col])\n",
        "                        print(f\"Coluna de data processada: {col}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Não foi possível processar a coluna de data {col}: {e}\")\n",
        "\n",
        "        # Lida com features categóricas (exemplo: codificação simples de rótulo ou one-hot baseada no limiar)\n",
        "        if self.categorical_features:\n",
        "             for col in self.categorical_features:\n",
        "                 if col in X_processed.columns:\n",
        "                    if X_processed[col].nunique() > self.categorical_threshold:\n",
        "                        # Muitos valores únicos, talvez remover ou aplicar uma estratégia diferente\n",
        "                        print(f\"Aviso: A coluna categórica '{col}' tem muitos valores únicos ({X_processed[col].nunique()}). Considere tratamento alternativo.\")\n",
        "                        # Exemplo: Remover coluna ou manter como está por enquanto, dependendo da estratégia\n",
        "                        # X_processed = X_processed.drop(columns=[col]) # Exemplo: removendo alta cardinalidade\n",
        "                    else:\n",
        "                         # Para demonstração, vamos mantê-las como estão antes do OneHotEncoding no pipeline do modelo\n",
        "                         pass # OneHotEncoding é tratado no pipeline do modelo\n",
        "\n",
        "        print(\"Pré-processamento concluído.\")\n",
        "        return X_processed\n",
        "\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"Realiza engenharia de features.\"\"\"\n",
        "    print(\"Realizando engenharia de features...\")\n",
        "    df_engineered = df.copy()\n",
        "\n",
        "    # Exemplo de engenharia de features: diferença entre ano de início e fim\n",
        "    if 'yearstart_year' in df_engineered.columns and 'yearend_year' in df_engineered.columns:\n",
        "        df_engineered['year_difference'] = df_engineered['yearend_year'] - df_engineered['yearstart_year']\n",
        "        print(\"Criada feature 'year_difference'.\")\n",
        "\n",
        "    # Exemplo: Termo de interação (se colunas relevantes existirem e forem numéricas)\n",
        "    # Verifica se as colunas 'Data_Value' e 'Sample_Size' são numéricas antes de multiplicar\n",
        "    if all(col in df_engineered.columns and pd.api.types.is_numeric_dtype(df_engineered[col]) for col in ['Data_Value', 'Sample_Size']):\n",
        "        df_engineered['value_sample_interaction'] = df_engineered['Data_Value'] * df_engineered['Sample_Size']\n",
        "        print(\"Criada feature 'value_sample_interaction'.\")\n",
        "    else:\n",
        "        # Lida com potenciais tipos não numéricos, se necessário, por exemplo, convertendo ou pulando a interação\n",
        "         if 'Data_Value' in df_engineered.columns and 'Sample_Size' in df_engineered.columns:\n",
        "            print(\"Pulando a criação da feature 'value_sample_interaction' devido a tipos não numéricos ou colunas ausentes.\")\n",
        "\n",
        "\n",
        "    print(\"Engenharia de features concluída.\")\n",
        "    return df_engineered\n",
        "\n",
        "def compare_models(X_train, y_train, X_test, y_test, preprocessor_pipe):\n",
        "    \"\"\"Compara a performance de diferentes modelos de regressão.\"\"\"\n",
        "    print(\"\\nComparando diferentes modelos...\")\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Random Forest': RandomForestRegressor(random_state=42),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
        "        'Support Vector Machine': SVR(kernel='rbf'),\n",
        "        'ElasticNet': ElasticNet(random_state=42),\n",
        "        'KNeighbors Regressor': KNeighborsRegressor()\n",
        "\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        try:\n",
        "            # Constrói um pipeline para cada modelo usando o preprocessor fornecido\n",
        "            pipeline = Pipeline(steps=[('preprocessor', preprocessor_pipe),\n",
        "                                       ('regressor', model)])\n",
        "\n",
        "            pipeline.fit(X_train, y_train)\n",
        "            y_pred = pipeline.predict(X_test)\n",
        "\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "            results.append({'Modelo': name, 'RMSE': rmse, 'R²': r2, 'MAE': mae})\n",
        "            print(f\"  - {name}: RMSE={rmse:.4f}, R²={r2:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  - Erro ao treinar/avaliar {name}: {str(e)}\")\n",
        "            results.append({'Modelo': name, 'RMSE': np.nan, 'R²': np.nan, 'MAE': np.nan})\n",
        "\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "    print(\"\\nResultados da comparação de modelos:\")\n",
        "    display(results_df)\n",
        "    return results_df\n",
        "\n",
        "def optimize_hyperparameters(base_model, param_grid, preprocessor_pipe, X_train, y_train):\n",
        "    \"\"\"Otimiza hiperparâmetros para um dado modelo usando RandomizedSearchCV.\"\"\"\n",
        "    print(f\"Otimizando hiperparâmetros para {type(base_model).__name__}...\")\n",
        "\n",
        "    # Cria um pipeline com o preprocessor e o modelo base\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor_pipe),\n",
        "                               ('regressor', base_model)])\n",
        "\n",
        "    if not param_grid:\n",
        "        print(\"Nenhuma grade de parâmetros fornecida para otimização. Usando o modelo base.\")\n",
        "        return pipeline.fit(X_train, y_train), {}\n",
        "\n",
        "    try:\n",
        "        # Usa RandomizedSearchCV\n",
        "        random_search = RandomizedSearchCV(\n",
        "            pipeline,\n",
        "            param_grid,\n",
        "            n_iter=20, # Número de configurações de parâmetros a serem amostradas\n",
        "            cv=KFold(n_splits=5, shuffle=True, random_state=42), # Usando validação cruzada KFold\n",
        "            scoring='neg_root_mean_squared_error', # Otimiza para RMSE\n",
        "            random_state=42,\n",
        "            n_jobs=-1, # Usa todos os núcleos disponíveis\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        print(f\"Melhores parâmetros encontrados: {random_search.best_params_}\")\n",
        "        print(f\"Melhor RMSE de validação cruzada: {-random_search.best_score_:.4f}\") # Observação: é o RMSE negativo\n",
        "\n",
        "        return random_search.best_estimator_, random_search.best_params_\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro durante a otimização de hiperparâmetros: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return pipeline.fit(X_train, y_train), {} # Retorna o pipeline do modelo base se a otimização falhar\n",
        "\n",
        "def compare_optimized_models(best_models, X_test, y_test):\n",
        "    \"\"\"Compara a performance de modelos otimizados.\"\"\"\n",
        "    print(\"\\nComparando modelos otimizados...\")\n",
        "    results = []\n",
        "\n",
        "    for name, model in best_models.items():\n",
        "        try:\n",
        "            y_pred = model.predict(X_test)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "            results.append({'Modelo': name, 'RMSE': rmse, 'R²': r2, 'MAE': mae})\n",
        "            print(f\"  - {name}: RMSE={rmse:.4f}, R²={r2:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  - Erro ao avaliar o modelo otimizado {name}: {str(e)}\")\n",
        "            results.append({'Modelo': name, 'RMSE': np.nan, 'R²': np.nan, 'MAE': np.nan})\n",
        "\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "    print(\"\\nResultados da comparação de modelos otimizados:\")\n",
        "    display(results_df)\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD6gjzw0PXBS"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# PASSO: 7 Comparação de Modelos\n",
        "# ====================================================\n",
        "def compare_models(X_train, y_train, X_test, y_test, preprocessor):\n",
        "    \"\"\"Treina e compara múltiplos modelos de regressão\"\"\"\n",
        "    models = {\n",
        "        'Gradient Boosting': GradientBoostingRegressor(\n",
        "            random_state=42, n_estimators=150, learning_rate=0.1, max_depth=5, min_samples_split=10\n",
        "        ),\n",
        "        'Random Forest': RandomForestRegressor(\n",
        "            random_state=42, n_estimators=100, max_depth=None, min_samples_split=2\n",
        "        ),\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Support Vector Machine': SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
        "        'ElasticNet': ElasticNet(random_state=42, alpha=0.1, l1_ratio=0.5)\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Criar pipeline completo\n",
        "            pipeline = Pipeline(steps=[\n",
        "                ('preprocessor', preprocessor),\n",
        "                ('regressor', model)\n",
        "            ])\n",
        "\n",
        "            # Treinar modelo\n",
        "            pipeline.fit(X_train, y_train)\n",
        "\n",
        "            # Fazer previsões\n",
        "            y_pred = pipeline.predict(X_test)\n",
        "\n",
        "            # Calcular métricas\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "            # Tempo de execução\n",
        "            train_time = time.time() - start_time\n",
        "\n",
        "            # Armazenar resultados\n",
        "            results.append({\n",
        "                'Modelo': name,\n",
        "                'RMSE': rmse,\n",
        "                'R²': r2,\n",
        "                'MAE': mae,\n",
        "                'MSE': mse,\n",
        "                'Tempo Treino (s)': train_time\n",
        "            })\n",
        "\n",
        "            print(f\"{name}: RMSE={rmse:.4f}, R²={r2:.4f}, MAE={mae:.4f}, Tempo={train_time:.2f}s\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao treinar {name}: {str(e)}\")\n",
        "\n",
        "    # Criar DataFrame de resultados\n",
        "    results_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "\n",
        "    # Plotar comparação de desempenho\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # RMSE\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.barplot(x='RMSE', y='Modelo', data=results_df, palette='viridis')\n",
        "    plt.title('Comparação de RMSE')\n",
        "    plt.xlabel('RMSE')\n",
        "\n",
        "    # R²\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sns.barplot(x='R²', y='Modelo', data=results_df, palette='viridis')\n",
        "    plt.title('Comparação de R²')\n",
        "    plt.xlabel('Coeficiente de Determinação (R²)')\n",
        "\n",
        "    # MAE\n",
        "    plt.subplot(2, 2, 3)\n",
        "    sns.barplot(x='MAE', y='Modelo', data=results_df, palette='viridis')\n",
        "    plt.title('Comparação de MAE')\n",
        "    plt.xlabel('Erro Absoluto Médio (MAE)')\n",
        "\n",
        "    # Tempo de Treino\n",
        "    plt.subplot(2, 2, 4)\n",
        "    sns.barplot(x='Tempo Treino (s)', y='Modelo', data=results_df, palette='viridis')\n",
        "    plt.title('Tempo de Treinamento')\n",
        "    plt.xlabel('Segundos')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('comparacao_modelos.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPARAÇÃO DE MODELOS\")\n",
        "    print(\"=\"*80)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Salvar resultados em CSV\n",
        "    results_df.to_csv('resultados_modelos.csv', index=False)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDse2wZzPeZL"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# PASSO: 8 Otimização de Hiperparâmetros\n",
        "# ====================================================\n",
        "def optimize_hyperparameters(model, param_grid, preprocessor, X_train, y_train):\n",
        "    \"\"\"Otimiza hiperparâmetros usando RandomizedSearchCV\"\"\"\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=20,\n",
        "        cv=5,\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(f\"\\nIniciando otimização para {type(model).__name__}...\") # Corrected attribute access\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Melhores parâmetros encontrados:\")\n",
        "    for param, value in search.best_params_.items():\n",
        "        print(f\"  {param}: {value}\")\n",
        "\n",
        "    return search.best_estimator_, search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA__7rOHPjga"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "#PASSO: 9 Comparação de Modelos Otimizados\n",
        "# ====================================================\n",
        "def compare_optimized_models(best_models, X_test, y_test):\n",
        "    \"\"\"Compara o desempenho dos modelos otimizados\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for name, model in best_models.items():\n",
        "        y_pred = model.predict(X_test)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "        results.append({\n",
        "            'Modelo': name,\n",
        "            'RMSE': rmse,\n",
        "            'R²': r2,\n",
        "            'MAE': mae\n",
        "        })\n",
        "\n",
        "    # Criar DataFrame de resultados\n",
        "    results_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "\n",
        "    # Plotar comparação\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.barplot(x='RMSE', y='Modelo', data=results_df, palette='viridis')\n",
        "    plt.title('Comparação de RMSE (Modelos Otimizados)')\n",
        "    plt.xlabel('RMSE')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.barplot(x='R²', y='Modelo', data=results_df, palette='viridis')\n",
        "    plt.title('Comparação de R² (Modelos Otimizados)')\n",
        "    plt.xlabel('Coeficiente de Determinação (R²)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('comparacao_modelos_otimizados.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPARAÇÃO DE MODELOS OTIMIZADOS\")\n",
        "    print(\"=\"*80)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Salvar resultados em CSV\n",
        "    results_df.to_csv('resultados_modelos_otimizados.csv', index=False)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfa07a4d",
        "outputId": "ca02a468-1b8d-4cd1-96a0-9edd7ce03209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dados de exemplo otimizados...\n",
            "Realizando limpeza básica de dados...\n",
            "Colunas originais: 6, Colunas após limpeza: 6\n",
            "Colunas de data identificadas: ['YearStart', 'YearEnd']\n",
            "Realizando pré-processamento de dados...\n",
            "Coluna de data processada: YearStart\n",
            "Coluna de data processada: YearEnd\n",
            "Pré-processamento concluído.\n",
            "Realizando engenharia de features...\n",
            "Engenharia de features concluída.\n",
            "Gradient Boosting: RMSE=6.6541, R²=-0.0319, MAE=5.5523, Tempo=0.20s\n",
            "Random Forest: RMSE=6.4377, R²=0.0341, MAE=5.4328, Tempo=0.31s\n",
            "Linear Regression: RMSE=6.4092, R²=0.0426, MAE=5.3296, Tempo=0.03s\n",
            "Support Vector Machine: RMSE=6.8315, R²=-0.0877, MAE=5.5241, Tempo=0.04s\n",
            "K-Nearest Neighbors: RMSE=6.6964, R²=-0.0451, MAE=5.7166, Tempo=0.03s\n",
            "ElasticNet: RMSE=6.4104, R²=0.0423, MAE=5.3427, Tempo=0.03s\n",
            "\n",
            "================================================================================\n",
            "COMPARAÇÃO DE MODELOS\n",
            "================================================================================\n",
            "                Modelo     RMSE        R²      MAE       MSE  Tempo Treino (s)\n",
            "     Linear Regression 6.409187  0.042640 5.329599 41.077681          0.030302\n",
            "            ElasticNet 6.410418  0.042273 5.342738 41.093454          0.027190\n",
            "         Random Forest 6.437734  0.034093 5.432807 41.444424          0.311315\n",
            "     Gradient Boosting 6.654096 -0.031923 5.552336 44.277000          0.200520\n",
            "   K-Nearest Neighbors 6.696370 -0.045077 5.716641 44.841373          0.026874\n",
            "Support Vector Machine 6.831509 -0.087683 5.524080 46.669515          0.044157\n",
            "\n",
            "Otimizando os melhores modelos: ['Linear Regression', 'ElasticNet']\n",
            "\n",
            "Iniciando otimização para LinearRegression...\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Melhores parâmetros encontrados:\n",
            "\n",
            "================================================================================\n",
            "COMPARAÇÃO DE MODELOS OTIMIZADOS\n",
            "================================================================================\n",
            "           Modelo     RMSE      R²      MAE\n",
            "Linear Regression 6.409187 0.04264 5.329599\n",
            "Melhor modelo (Linear Regression) salvo como 'best_model.pkl'\n",
            "✅ Visualizações salvas como 'analise_obesidade_diagnostico.png'\n",
            "\n",
            "================================================================================\n",
            "PROCESSO CONCLUÍDO COM SUCESSO!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import pandas as pd\n",
        "    import joblib\n",
        "    from scipy.stats import randint, uniform\n",
        "    import traceback\n",
        "    import re\n",
        "\n",
        "    # Carregar dados\n",
        "    try:\n",
        "        # Substitua com seu carregamento real de dados\n",
        "        # df = pd.read_csv('obesity_data.csv')\n",
        "\n",
        "        # Dados de exemplo otimizados para testes rápidos\n",
        "        print(\"Usando dados de exemplo otimizados...\")\n",
        "        data = {\n",
        "            'YearStart': list(range(2010, 2020)) * 10,\n",
        "            'YearEnd': list(range(2010, 2020)) * 10,\n",
        "            'LocationDesc': ['Alabama', 'Alaska', 'Arizona'] * 33 + ['California'],\n",
        "            'StratificationCategory1': ['Total', 'Gender', 'Education'] * 33 + ['Income'],\n",
        "            'Data_Value': np.random.uniform(20, 40, 100),\n",
        "            'Sample_Size': np.random.randint(100, 1000, 100)\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "        df.rename(columns={'Data_Value': 'obesity_rate'}, inplace=True)\n",
        "\n",
        "        # Executar o fluxo principal\n",
        "        main(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar dados: {str(e)}\")\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
